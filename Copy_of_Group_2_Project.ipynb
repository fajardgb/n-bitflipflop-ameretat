{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fajardgb/n-bitflipflop-ameretat/blob/main/Copy_of_Group_2_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "OS0S3-5yTK8j"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/projects/project-notebooks/ComparingNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/projects/project-notebooks/ComparingNetworks.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##steps for notebook\n",
        "# import repos and install packages\n",
        "# create 3BFF env\n",
        "# train GRU and NODE\n",
        "# fit affine transformation btwn them\n",
        "# find fixed points btwn them\n",
        "# train 2 more models  (RNN, LSTM) --> maybe just the LSTM?\n",
        "# compare their activity using DSA -- 6 comparisons\n",
        "# create a 4BFF and repeat the DSA analysis\n",
        "# compare complexities of the 2 tasks (??)\n",
        "\n",
        "###in the chart, they suggest DSA on the 1st two (GRU vs NODE) and then DSA on 4BFF with GRU vs LSTM"
      ],
      "metadata": {
        "id": "h761Db2ecxCz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jtVHJ6t6FRI",
        "outputId": "9c0d9cc2-b010-4f39-9eec-e395e1ef2a3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/fajardgb/random-target-ameretat.git"
      ],
      "metadata": {
        "id": "K-Zz67TH6xq1",
        "outputId": "69f964bb-47f8-41ab-e6ba-b034e70d2462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'random-target-ameretat'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 76 (delta 21), reused 22 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 7.22 MiB | 10.07 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/fajardgb/n-bitflipflop-ameretat"
      ],
      "metadata": {
        "id": "q1hSmJBL69E7",
        "outputId": "4a152d61-fc08-4109-e306-85ddbd2437c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'n-bitflipflop-ameretat'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 58 (delta 20), reused 28 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (58/58), 20.34 MiB | 11.44 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {},
        "id": "_JnSexOYTK8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a197acd3-d52c-41db-8fe7-0331178a62fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComputationThruDynamicsBenchmark'...\n",
            "remote: Enumerating objects: 3359, done.\u001b[K\n",
            "remote: Counting objects: 100% (585/585), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 3359 (delta 519), reused 501 (delta 501), pack-reused 2774 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3359/3359), 296.08 MiB | 32.61 MiB/s, done.\n",
            "Resolving deltas: 100% (1883/1883), done.\n",
            "Updating files: 100% (262/262), done.\n",
            "/content/ComputationThruDynamicsBenchmark\n",
            "Obtaining file:///content/ComputationThruDynamicsBenchmark\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (2.6.0+cu124)\n",
            "Collecting torchmetrics==1.3.0.post0 (from ctd==1.0)\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pytorch-lightning==2.1.3 (from ctd==1.0)\n",
            "  Downloading pytorch_lightning-2.1.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting ray[tune] (from ctd==1.0)\n",
            "  Downloading ray-2.48.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (2.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (0.21.0)\n",
            "Collecting hydra-core (from ctd==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (1.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (3.14.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (3.10.0)\n",
            "Collecting python-dotenv (from ctd==1.0)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (2.37.0)\n",
            "Collecting motornet (from ctd==1.0)\n",
            "  Downloading motornet-0.2.0.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (7.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from ctd==1.0) (4.12.0.88)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3->ctd==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3->ctd==1.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3->ctd==1.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3->ctd==1.0) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3->ctd==1.0) (4.14.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning==2.1.3->ctd==1.0)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->ctd==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->ctd==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->ctd==1.0) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium->ctd==1.0) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium->ctd==1.0) (0.0.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core->ctd==1.0) (4.9.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]->ctd==1.0) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]->ctd==1.0) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]->ctd==1.0) (5.9.5)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->ctd==1.0) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->ctd==1.0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->ctd==1.0) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->ctd==1.0) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ctd==1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (8.2.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (4.25.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (1.1.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]->ctd==1.0)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]->ctd==1.0) (18.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ctd==1.0) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ctd==1.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ctd==1.0) (3.6.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->ctd==1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->ctd==1.0) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->ctd==1.0) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->ctd==1.0) (2.33.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (3.11.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->ctd==1.0) (4.0.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->ctd==1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->ctd==1.0) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->ctd==1.0) (5.8.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->ctd==1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->ctd==1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->ctd==1.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->ctd==1.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]->ctd==1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]->ctd==1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]->ctd==1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]->ctd==1.0) (2025.7.14)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.1->ctd==1.0) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]->ctd==1.0) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]->ctd==1.0) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]->ctd==1.0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]->ctd==1.0) (0.26.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]->ctd==1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]->ctd==1.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3->ctd==1.0) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->ctd==1.0) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->ctd==1.0) (0.8.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->ctd==1.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->ctd==1.0) (0.2.13)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (2.21.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ctd==1.0) (1.3.1)\n",
            "Downloading pytorch_lightning-2.1.3-py3-none-any.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.48.0-cp311-cp311-manylinux2014_x86_64.whl (70.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: motornet\n",
            "  Building wheel for motornet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for motornet: filename=motornet-0.2.0-py3-none-any.whl size=51743 sha256=ccdb4169824534441be85f13f468b5edc6ccce1a667278d3e122829c56fc4355\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/a0/8f/541fb3ede746ac7fa7c17a1cc31053a75cac3e6970ce8e88f3\n",
            "Successfully built motornet\n",
            "Installing collected packages: tensorboardX, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, ray, torchmetrics, motornet, pytorch-lightning, ctd\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Running setup.py develop for ctd\n",
            "Successfully installed ctd-1.0 hydra-core-1.3.2 jedi-0.19.2 lightning-utilities-0.14.3 motornet-0.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-dotenv-1.1.1 pytorch-lightning-2.1.3 ray-2.48.0 tensorboardX-2.6.4 torchmetrics-1.3.0.post0\n"
          ]
        }
      ],
      "source": [
        "#get ctd repo\n",
        "\n",
        "! git clone https://github.com/neuromatch/ComputationThruDynamicsBenchmark #ctd/task_modeling/model/rnn.py - path for model architecture creation\n",
        "%cd ComputationThruDynamicsBenchmark\n",
        "! pip install -e .\n",
        "\n",
        "# RUN THIS CELL, THEN RESTART SESSION AS PROMPTED (BUTTON AT BOTTOM OF THIS CELL'S FINISHED OUTPUT). DO NOT NEED TO RUN AGAIN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {},
        "id": "YigDLtj6TK8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3c67f8-f199-4dc8-a403-db259f23a201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComputationThruDynamicsBenchmark\n"
          ]
        }
      ],
      "source": [
        "## GET BACK TO THE DIRECTORY AND CONFIGURE .env\n",
        "\n",
        "%cd /content/ComputationThruDynamicsBenchmark/\n",
        "envStr = \"\"\"HOME_DIR=/content/ComputationThruDynamicsBenchmark/\n",
        "TRAIN_INPUT_FILE=train_input.h5\\nEVAL_INPUT_FILE=eval_input.h5\n",
        "EVAL_TARGET_FILE=eval_target.h5\n",
        "\"\"\"\n",
        "\n",
        "with open('.env','w') as f:\n",
        "  f.write(envStr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {},
        "id": "pA8ywqeaTK8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5dad90-fb55-4db7-f5c2-9b206cfd8a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DSA'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 393 (delta 52), reused 49 (delta 25), pack-reused 304 (from 1)\u001b[K\n",
            "Receiving objects: 100% (393/393), 1.53 MiB | 14.41 MiB/s, done.\n",
            "Resolving deltas: 100% (225/225), done.\n",
            "/content/ComputationThruDynamicsBenchmark/DSA\n",
            "Obtaining file:///content/ComputationThruDynamicsBenchmark/DSA\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from DSA==1.0.1) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from DSA==1.0.1) (2.6.0+cu124)\n",
            "Collecting kooplearn>=1.1.0 (from DSA==1.0.1)\n",
            "  Downloading kooplearn-1.1.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pot (from DSA==1.0.1)\n",
            "  Downloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from kooplearn>=1.1.0->DSA==1.0.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from kooplearn>=1.1.0->DSA==1.0.1) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kooplearn>=1.1.0->DSA==1.0.1) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->DSA==1.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->DSA==1.0.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->DSA==1.0.1) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->kooplearn>=1.1.0->DSA==1.0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->kooplearn>=1.1.0->DSA==1.0.1) (3.6.0)\n",
            "Downloading kooplearn-1.1.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pot, kooplearn, DSA\n",
            "  Running setup.py develop for DSA\n",
            "Successfully installed DSA-1.0.1 kooplearn-1.1.3 pot-0.9.5\n"
          ]
        }
      ],
      "source": [
        "#get DSA repo\n",
        "\n",
        "!git clone https://github.com/mitchellostrow/DSA\n",
        "%cd DSA/\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {},
        "id": "8qVBZSF-TK8p",
        "outputId": "b8657a5c-ec3c-4e7c-fc36-eae7c72ce442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# set the random seed for reproducibility\n",
        "import random\n",
        "import dotenv\n",
        "import pathlib\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# comment the next three lines if you want to see all training logs\n",
        "pl_loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict if 'pytorch_lightning' in name]\n",
        "for pl_log in pl_loggers:\n",
        "    logging.getLogger(pl_log.name).setLevel(logging.WARNING)\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "dotenv.load_dotenv(override=True)\n",
        "#HOME_DIR = os.getenv('HOME_DIR')\n",
        "HOME_DIR = '/content'\n",
        "if HOME_DIR is None:\n",
        "    HOME_DIR = \"\"\n",
        "print(HOME_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import the trained models**"
      ],
      "metadata": {
        "id": "lfFk92mmegK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "os.environ['HOME_DIR'] = '/content'\n",
        "\n",
        "\n",
        "#get GRU model for 3bff\n",
        "gru_path = pathlib.Path(HOME_DIR) / 'n-bitflipflop-ameretat' / 'models' / '3-bit' / 'models_GRU_128' / \"\"\n",
        "\n",
        "#try gru_path = HOME_DIR.joinpath('/n-bitflipflop-ameretat/models')\n",
        "\n",
        "# import datamodule\n",
        "rnn_data_module = pickle.load(open(gru_path / 'datamodule_sim.pkl', 'rb'))\n",
        "\n",
        "rnn_model = pickle.load(open(gru_path / 'model.pkl', 'rb'))\n",
        "\n",
        "print(gru_path)"
      ],
      "metadata": {
        "id": "HUEWlk1mqewk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "870f1fb8-a4cf-4af6-cf20-9269a15720ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ctd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-2805710627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mctd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_modeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNBitFlipFlop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME_DIR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ctd'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the saved NODE model for 3bff\n",
        "\n",
        "node_path = pathlib.Path(HOME_DIR) / 'n-bitflipflop-ameretat' / 'models' / '3-bit' / 'models_NODE_3' / \"\"\n",
        "\n",
        "# import datamodule\n",
        "node_data_module = pickle.load(open(node_path / 'datamodule_sim.pkl', 'rb'))\n",
        "\n",
        "node_model = pickle.load(open(node_path / 'model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "7dtg_rEYq_nJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "c21327c4-b502-4e91-e0ba-12b950dfc1cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ctd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-973231296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import datamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnode_data_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'datamodule_sim.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnode_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ctd'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inspect latent activity between the 2 models**"
      ],
      "metadata": {
        "id": "XMaGcnnMinbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ctd.comparison.analysis.tt.tt import Analysis_TT\n",
        "import ctd.task_modeling.datamodule.task_datamodule as task_dm\n",
        "#this is a temporary patch to fix a path issue\n",
        "\n",
        "task_dm.HOME_DIR = '/content'\n",
        "\n",
        "filepath_with_slash = str(gru_path) + '/'\n",
        "\n",
        "# Then try creating your analysis object\n",
        "analysis_GRU_128 = Analysis_TT(\n",
        "    run_name = \"GRU_128_3bff\",\n",
        "    filepath = filepath_with_slash)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "B2EB9ooHDecm",
        "outputId": "94a8cf7f-ba6b-4147-f66e-90c1dea53727"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ctd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-1725821536.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mctd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnalysis_TT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_modeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_datamodule\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtask_dm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#this is a temporary patch to fix a path issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask_dm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOME_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ctd'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ivNLS9deDeSJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "nkBQj7H-TK8y"
      },
      "outputs": [],
      "source": [
        "# same as above but for NODE\n",
        "\n",
        "nodepath_with_slash = str(node_path) + '/'\n",
        "\n",
        "analysis_NODE = Analysis_TT(\n",
        "    run_name = \"NODE_3_3bff\",\n",
        "    filepath = nodepath_with_slash)\n",
        "\n",
        "analysis_NODE.plot_trial_io(num_trials = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "0vstv1EbTK8y"
      },
      "source": [
        "Importantly, the analysis object also provides functions that give access to the raw latent activity, predicted outputs, etc. of the trained models! All of these functions accept a \"phase\" variable that designates whether to return the training and/or validation datasets.\n",
        "These functions are:\n",
        "- `get_latents()`: Returns latent activity of the trained model\n",
        "- `get_inputs()`: Returns the inputs to the model (for 3BFF, the input pulses)\n",
        "- `get_model_output()`: Returns a dict that contains all model outputs:\n",
        "  - controlled - the variable that the model is controlling\n",
        "  - latents - the latent activity\n",
        "  - actions - the output from the model (for RandomTarget only)\n",
        "  - states - the state of the environment (for RandomTarget only)\n",
        "  - joints - Joint angles (for RandomTarget only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "4sh6-XGzTK8y"
      },
      "outputs": [],
      "source": [
        "print(f\"All data shape: {analysis_GRU_128.get_latents().shape}\")\n",
        "print(f\"Train data shape: {analysis_GRU_128.get_latents(phase = 'train').shape}\")\n",
        "print(f\"Validation data shape: {analysis_GRU_128.get_latents(phase = 'val').shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "llACxKNmTK8y"
      },
      "source": [
        "# **Use affine transformations to compare latent activity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "eyrFS6T3TK8y"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "source = analysis_GRU_128\n",
        "target = analysis_NODE\n",
        "\n",
        "# Get the latent activity from the validation phase for each model:\n",
        "\n",
        "latents_source = source.get_latents(phase='train').detach().numpy()\n",
        "latents_targ = target.get_latents(phase='train').detach().numpy()\n",
        "\n",
        "latents_source_val = source.get_latents(phase='val').detach().numpy()\n",
        "latents_targ_val = target.get_latents(phase='val').detach().numpy()\n",
        "\n",
        "n_trials, n_timesteps, n_latent_source = latents_source.shape\n",
        "n_trials, n_timesteps, n_latent_targ = latents_targ.shape\n",
        "\n",
        "n_trials_val, n_timesteps_val, n_latent_source_val = latents_source_val.shape\n",
        "n_trials_val, n_timesteps_val, n_latent_targ_val = latents_targ_val.shape\n",
        "\n",
        "print(f\"Latent shape for source model: {latents_source.shape}\"\n",
        "      f\"\\nLatent shape for target model: {latents_targ.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "zl7vJF-iTK8y"
      },
      "outputs": [],
      "source": [
        "# Perform PCA on both latent spaces to find axes of highest variance\n",
        "\n",
        "pca_source = PCA()\n",
        "pca_targ = PCA()\n",
        "lats_source_pca = pca_source.fit_transform(latents_source.reshape(-1, n_latent_source)).reshape((n_trials, n_timesteps, -1))\n",
        "lats_source_pca_val = pca_source.transform(latents_source_val.reshape(-1, n_latent_source)).reshape((n_trials, n_timesteps, -1))\n",
        "\n",
        "lats_targ_pca = pca_targ.fit_transform(latents_targ.reshape(-1, n_latent_targ)).reshape((n_trials, n_timesteps, -1))\n",
        "lats_targ_pca_val = pca_targ.transform(latents_targ_val.reshape(-1, n_latent_targ_val)).reshape((n_trials_val, n_timesteps_val, -1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a linear regression model to predict the target latents from the source latents\n",
        "\n",
        "reg = LinearRegression().fit(lats_source_pca.reshape(-1, n_latent_source), lats_targ_pca.reshape(-1, n_latent_targ))\n",
        "# Get the R2 of the fit\n",
        "preds = reg.predict(lats_source_pca_val.reshape(-1, n_latent_source_val))\n",
        "r2s = r2_score(lats_targ_pca_val.reshape((-1, n_latent_targ_val)), preds,  multioutput = \"raw_values\")\n",
        "r2_var = r2_score(lats_targ_pca_val.reshape((-1, n_latent_targ_val)), preds, multioutput = \"variance_weighted\")\n",
        "print(f\"R2 of linear regression fit: {r2s}\")\n",
        "print(f\"Variance-weighted R2 of linear regression fit: {r2_var}\")"
      ],
      "metadata": {
        "id": "Lw0RsWJ6nqU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Explain what is happening;  interpret the above results***\n",
        "\n"
      ],
      "metadata": {
        "id": "q8Uv8hPdjDiO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NaXiCH_uTK8y"
      },
      "source": [
        "So, the variance weighted R2 from the source to the target is ~0.93.\n",
        "\n",
        "*Try reversing the direction (the source as NODE and target as GRU) and see how well the model fits*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "rVdjaiVZTK8z"
      },
      "outputs": [],
      "source": [
        "from ctd.comparison.comparison import Comparison\n",
        "\n",
        "# compare latent activity via affine transformation\n",
        "# this should produce a plot\n",
        "\n",
        "comp = Comparison()\n",
        "comp.load_analysis(analysis_GRU_128, reference_analysis=True)\n",
        "comp.load_analysis(analysis_NODE)\n",
        "comp.plot_trials_3d_reference(num_trials=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Find fixed points between the GRU and NODE**"
      ],
      "metadata": {
        "id": "C0gcdIRCji6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use fixed-point finding to inspect the linearized dynamics of the trained model.\n",
        "\n",
        "Fixed points are points in the dynamics for which the flow field is zero, meaning that points at that location do not move."
      ],
      "metadata": {
        "id": "l9UtiO9VjdQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "Ozk-uAazTK8z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
        "    fps = analysis_GRU_128.plot_fps(\n",
        "        inputs= torch.zeros(3),\n",
        "        n_inits=1024,\n",
        "        learning_rate=1e-3,\n",
        "        noise_scale=0.0,\n",
        "        max_iters=20000,\n",
        "        seed=0,\n",
        "        compute_jacobians=True,\n",
        "        q_thresh=1e-5,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Explain what we are seeing above; how to interpret\n",
        "What is the Q value?  What does it tell us?\n",
        "Whta do the fixed points tell you about the computation for 3BFF?"
      ],
      "metadata": {
        "id": "ptl7h0NYjq3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
        "    fps = analysis_NODE.plot_fps(\n",
        "        inputs= torch.zeros(3),\n",
        "        n_inits=1024,\n",
        "        learning_rate=1e-3,\n",
        "        noise_scale=0.0,\n",
        "        max_iters=20000,\n",
        "        seed=0,\n",
        "        compute_jacobians=True,\n",
        "        q_thresh=1e-5,\n",
        "    )"
      ],
      "metadata": {
        "id": "B7ls-18bobwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train an LSTM network**"
      ],
      "metadata": {
        "id": "GpHbcQ5ey01D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train another model(s) -- start w LSTM, then maybe basic RNN or something else\n",
        "\n",
        "\n",
        "#lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1)\n",
        "# may not be able to just import this from nn.module since it needs to approximate the GRU_Cell\n",
        "# look in rnn.py to read the requirements\n"
      ],
      "metadata": {
        "id": "QDkoW0vTjwQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and visualize the latent dynamics"
      ],
      "metadata": {
        "id": "Nigj5nYN0aqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DSA: GRU vs NODE**"
      ],
      "metadata": {
        "id": "GBEKd-rgzw4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(latents_source_val.shape)\n",
        "print(latents_targ_val.shape)"
      ],
      "metadata": {
        "id": "r0shZp1nGeP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Do DSA on the GRU vs NODE\n",
        "from DSA import DSA\n",
        "\n",
        "traj_gru = latents_source_val.reshape(-1, latents_source_val.shape[-1])  # shape: (n_trials*n_timesteps, n_latents)\n",
        "traj_node = latents_targ_val.reshape(-1, latents_targ_val.shape[-1])\n",
        "\n",
        "# # Run DSA\n",
        "n_delays = 20\n",
        "delay_interval = 10\n",
        "\n",
        "dsa = DSA(X=traj_gru, Y=traj_node, n_delays=n_delays, delay_interval=delay_interval)\n",
        "similarity = dsa.fit_score()\n",
        "print(f\"DSA similarity between GRU and NODE: {similarities:.4f}\")"
      ],
      "metadata": {
        "id": "_YmBUDAbE00f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 25  # Creates 20 chunks per trial (500/25)\n",
        "\n",
        "# Reshape into chunks\n",
        "n_trials, n_timesteps = 200, 500\n",
        "n_chunks = n_timesteps // chunk_size\n",
        "\n",
        "gru_chunks = latents_source_val[:, :n_chunks*chunk_size, :].reshape(\n",
        "    n_trials * n_chunks, chunk_size * 128  # (4000, 3200)\n",
        ")\n",
        "\n",
        "node_chunks = latents_targ_val[:, :n_chunks*chunk_size, :].reshape(\n",
        "    n_trials * n_chunks, chunk_size * 3    # (4000, 75)\n",
        ")\n"
      ],
      "metadata": {
        "id": "q3-0-oboIIwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce GRU chunks to match NODE structure\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "gru_scaled = scaler.fit_transform(gru_chunks)\n",
        "\n",
        "pca = PCA(n_components=75)  # Match NODE chunk dimension\n",
        "gru_reduced = pca.fit_transform(gru_scaled)\n",
        "\n",
        "# Run DSA\n",
        "dsa = DSA(X=gru_reduced, Y=node_chunks, n_delays=5, delay_interval=2)\n",
        "similarity = dsa.fit_score()\n",
        "print(f\"DSA similarity: {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "ojyZDST1ILG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Reduce GRU from 128 to 3 features FIRST\n",
        "gru_flat = latents_source_val.reshape(-1, 128)  # (100000, 128)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "gru_scaled = scaler.fit_transform(gru_flat)\n",
        "\n",
        "pca = PCA(n_components=3)  # Match NODE's 3 features\n",
        "gru_reduced_flat = pca.fit_transform(gru_scaled)\n",
        "\n",
        "# Step 2: Reshape back to original structure\n",
        "gru_reduced = gru_reduced_flat.reshape(200, 500, 3)  # Now (200, 500, 3)\n",
        "\n",
        "print(f\"GRU explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
        "\n",
        "# Step 3: Now chunk with EQUAL dimensions\n",
        "chunk_size = 25\n",
        "n_chunks = 500 // chunk_size\n",
        "\n",
        "gru_chunks = gru_reduced[:, :n_chunks*chunk_size, :].reshape(\n",
        "    200 * n_chunks, chunk_size * 3  # (4000, 75)\n",
        ")\n",
        "\n",
        "node_chunks = latents_targ_val[:, :n_chunks*chunk_size, :].reshape(\n",
        "    200 * n_chunks, chunk_size * 3  # (4000, 75)\n",
        ")\n",
        "\n",
        "print(f\"Perfect match! GRU: {gru_chunks.shape}, NODE: {node_chunks.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rCbTlcv6I4fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Run DSA\n",
        "dsa = DSA(X=gru_chunks, Y=node_chunks, n_delays=5, delay_interval=2)\n",
        "similarity = dsa.fit_score()\n",
        "print(f\"DSA similarity: {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "WkIgpZcII68D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "labels = ['GRU', 'NODE']\n",
        "plt.bar(similarity, xticklabels=labels, yticklabels=labels)\n",
        "cbar = ax.collections[0].colorbar\n",
        "cbar.ax.set_ylabel('DSA Score');\n",
        "plt.title(\"Dynamic Similarity Analysis Score among Trajectories\");"
      ],
      "metadata": {
        "id": "2s05I9LHLHYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DSA: GRU vs VanillaRNN**"
      ],
      "metadata": {
        "id": "jHeoi6Usz0-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do DSA on the GRU vs RNN since dims are simliar (same 128 features)"
      ],
      "metadata": {
        "id": "t68QxdQXcTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explain how they are simliar, interpret the results"
      ],
      "metadata": {
        "id": "E6kYMAqTcTEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4BFF task**"
      ],
      "metadata": {
        "id": "ihR6C16E0fL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 4BFF task and repeat!"
      ],
      "metadata": {
        "id": "Zi8E3I48cS_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_4bff = NBitFlipFlop(\n",
        "    n = 4,\n",
        "    n_timesteps=trial_length,\n",
        "    switch_prob=switch_prob,\n",
        "    noise=noise\n",
        "    )\n",
        "\n",
        "# Renders a random trial from the environment\n",
        "env_4bff.render()"
      ],
      "metadata": {
        "id": "nORwCbyjlNjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add code to visualize the hypercube"
      ],
      "metadata": {
        "id": "O-wl7sN7lUbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train GRU, NODE, and LSTM on 4BFF and save models\n",
        "# here we should once again import the saved models"
      ],
      "metadata": {
        "id": "YVv8IHji1zWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rerun: affine? fixed point? DSA?"
      ],
      "metadata": {
        "id": "9RLe1nCw1zTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "talk about the simliarities/differences between 3 bit and 4\n"
      ],
      "metadata": {
        "id": "AlyIkErilXjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the complexities of the task?  Not sure how to do that exactly"
      ],
      "metadata": {
        "id": "2gt-bkWWcS8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "4juq83N4lBgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "discussion\n"
      ],
      "metadata": {
        "id": "z3_K548alF6B"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}